{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a42b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "class PokerB:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.nodeMap = {}\n",
    "        self.expected_game_value = 0\n",
    "        self.n_cards = 10\n",
    "        self.nash_equilibrium = dict()\n",
    "        self.current_player = 0\n",
    "        self.deck = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "        self.n_actions = 2\n",
    "    \n",
    "    def randomHand(self):\n",
    "        for i in range(1,2):\n",
    "            r = np.random(2598960)\n",
    "            if r<1302540:\n",
    "                  self.deck[i]=0\n",
    "            if 1302540<r<1302540+1098240:\n",
    "                self.deck[i]=1\n",
    "            if 1302540+1098240<r<1302540+1098240+123552:\n",
    "                self.deck[i]=2\n",
    "            if 1302540+1098240+123552+54912<r<1302540+1098240+123552+54912+10200:\n",
    "                self.deck[i]=3\n",
    "            if 1302540+1098240+123552+54912+10200<r<1302540+1098240+123552+54912+10200+5108:\n",
    "                self.deck[i]=4\n",
    "            if 1302540+1098240+123552+54912+10200+5108<r<1302540+1098240+123552+54912+10200+5108+3744:\n",
    "                self.deck[i]=5\n",
    "            if 1302540+1098240+123552+54912+10200+5108+3744<r<1302540+1098240+123552+54912+10200+5108+3744+624:\n",
    "                self.deck[i]=6\n",
    "            if 1302540+1098240+123552+54912+10200+5108+3744+624<r<1302540+1098240+123552+54912+10200+5108+3744+624+36:\n",
    "                self.deck[i]=7\n",
    "            if 1302540+1098240+123552+54912+10200+5108+3744+624+36<r<1302540+1098240+123552+54912+10200+5108+3744+624+36+4:\n",
    "                self.deck[i]=8\n",
    "            if r>1302540+1098240+123552+54912+10200+5108+3744+624+36+4:\n",
    "                self.deck[i]=9\n",
    "        \n",
    "        \n",
    "    def train(self, n_iterations=50000):\n",
    "        expected_game_value = 0\n",
    "        for _ in range(n_iterations):\n",
    "            shuffle(self.deck)\n",
    "            expected_game_value += self.cfr('', 1, 1)\n",
    "            for _, v in self.nodeMap.items():\n",
    "                v.update_strategy()\n",
    "\n",
    "        expected_game_value /= n_iterations\n",
    "        display_results(expected_game_value, self.nodeMap)\n",
    "\n",
    "    def cfr(self, history, pr_1, pr_2):\n",
    "        n = len(history)\n",
    "        is_player_1 = n % 2 == 0\n",
    "        player_card = self.deck[0] if is_player_1 else self.deck[1]  \n",
    "\n",
    "        if self.is_terminal(history):\n",
    "            card_player = self.deck[0] if is_player_1 else self.deck[1]\n",
    "            card_opponent = self.deck[1] if is_player_1 else self.deck[0]\n",
    "            reward = self.get_reward(history, card_player, card_opponent)\n",
    "            return reward\n",
    "\n",
    "        node = self.get_node(player_card, history)\n",
    "        strategy = node.strategy\n",
    "\n",
    "        # Counterfactual utility per action.\n",
    "        action_utils = np.zeros(self.n_actions)\n",
    "\n",
    "        for act in range(self.n_actions):\n",
    "            next_history = history + node.action_dict[act]\n",
    "            if is_player_1:\n",
    "                action_utils[act] = -1 * self.cfr(next_history, pr_1 * strategy[act], pr_2)\n",
    "            else:\n",
    "                action_utils[act] = -1 * self.cfr(next_history, pr_1, pr_2 * strategy[act])\n",
    "\n",
    "        # Utility of information set.\n",
    "        util = sum(action_utils * strategy)\n",
    "        regrets = action_utils - util\n",
    "        if is_player_1:\n",
    "            node.reach_pr += pr_1\n",
    "            node.regret_sum += pr_2 * regrets\n",
    "        else:\n",
    "            node.reach_pr += pr_2\n",
    "            node.regret_sum += pr_1 * regrets\n",
    "\n",
    "        return util\n",
    "\n",
    "    @staticmethod\n",
    "    def is_terminal(history):\n",
    "        if history[-2:] == 'pp' or history[-2:] == \"bb\" or history[-2:] == 'bp':\n",
    "            return True\n",
    "\n",
    "    @staticmethod\n",
    "    def get_reward(history, player_card, opponent_card):\n",
    "        terminal_pass = history[-1] == 'p'\n",
    "        double_bet = history[-2:] == \"bb\"\n",
    "        if terminal_pass:\n",
    "            if history[-2:] == 'pp':\n",
    "                if player_card > opponent_card:\n",
    "                    return 1\n",
    "                if player_card==opponent_card:\n",
    "                    return (0)\n",
    "                else :\n",
    "                    return (-1)\n",
    "            else:\n",
    "                return 1\n",
    "        elif double_bet:\n",
    "            if player_card > opponent_card:\n",
    "                return 2\n",
    "            if player_card==opponent_card:\n",
    "                return (0)\n",
    "            else :\n",
    "                return (-2)\n",
    "\n",
    "\n",
    "    def get_node(self, card, history):\n",
    "        key = str(card) + \" \" + history\n",
    "        if key not in self.nodeMap:\n",
    "            action_dict = {0: 'p', 1: 'b'}\n",
    "            info_set = Node(key, action_dict)\n",
    "            self.nodeMap[key] = info_set\n",
    "            return info_set\n",
    "        return self.nodeMap[key]\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, key, action_dict, n_actions=2):\n",
    "        self.key = key\n",
    "        self.n_actions = n_actions\n",
    "        self.regret_sum = np.zeros(self.n_actions)\n",
    "        self.strategy_sum = np.zeros(self.n_actions)\n",
    "        self.action_dict = action_dict\n",
    "        self.strategy = np.repeat(1/self.n_actions, self.n_actions)\n",
    "        self.reach_pr = 0\n",
    "        self.reach_pr_sum = 0\n",
    "\n",
    "    def update_strategy(self):\n",
    "        self.strategy_sum += self.reach_pr * self.strategy\n",
    "        self.reach_pr_sum += self.reach_pr\n",
    "        self.strategy = self.get_strategy()\n",
    "        self.reach_pr = 0\n",
    "\n",
    "    def get_strategy(self):\n",
    "        regrets = self.regret_sum\n",
    "        regrets[regrets < 0] = 0\n",
    "        normalizing_sum = sum(regrets)\n",
    "        if normalizing_sum > 0:\n",
    "            return regrets / normalizing_sum\n",
    "        else:\n",
    "            return np.repeat(1/self.n_actions, self.n_actions)\n",
    "\n",
    "    def get_average_strategy(self):\n",
    "        strategy = self.strategy_sum / self.reach_pr_sum\n",
    "        # Re-normalize\n",
    "        total = sum(strategy)\n",
    "        strategy /= total\n",
    "        return strategy\n",
    "\n",
    "    def __str__(self):\n",
    "        strategies = ['{:03.2f}'.format(x)\n",
    "                      for x in self.get_average_strategy()]\n",
    "        return '{} {}'.format(self.key.ljust(6), strategies)\n",
    "\n",
    "\n",
    "def display_results(ev, i_map):\n",
    "    print('player 1 expected value: {}'.format(ev))\n",
    "    print('player 2 expected value: {}'.format(-1 * ev))\n",
    "\n",
    "    print()\n",
    "    print('player 1 strategies:')\n",
    "    sorted_items = sorted(i_map.items(), key=lambda x: x[0])\n",
    "    for _, v in filter(lambda x: len(x[0]) % 2 == 0, sorted_items):\n",
    "        print(v)\n",
    "    print()\n",
    "    print('player 2 strategies:')\n",
    "    for _, v in filter(lambda x: len(x[0]) % 2 == 1, sorted_items):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    time1 = time.time()\n",
    "    trainer = PokerB()\n",
    "    trainer.train(n_iterations=25000)\n",
    "    print(abs(time1 - time.time()))\n",
    "    print(sys.getsizeof(trainer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
